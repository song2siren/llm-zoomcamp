{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8524f3-0c15-4fea-8a3a-8d8f81ee79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fastembed\n",
    "\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b6dd35-ee46-4d75-bd7d-921118e8f12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cbd7ce6cbe4c6a995925a661b4bc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b44e26cc3d447aa764507df02bade3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2029966b6c3d4bf19006b28847d7cfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb5629e006b4a3e815e1d1f1e5d64c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d805fa87a1743ceabb8ce7212cd09e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15768b8de23849d592944fd218f95999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 512\n",
      "Minimal value in the embedding array: -0.11726373885183883\n",
      "Normalised length of the embedding vector: 1.0\n",
      "Cosine of the query vector with itself: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Q1. Embedding the query\n",
    "\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "query_embeddings_generator = embedding_model.embed(query)\n",
    "query_embeddings_list = list(query_embeddings_generator)\n",
    "query_vector = query_embeddings_list[0];\n",
    "\n",
    "print(f\"Embedding Dimension: {len(query_vector)}\")\n",
    "\n",
    "min_value = np.min(query_vector)\n",
    "print(f\"Minimal value in the embedding array: {min_value}\")\n",
    "\n",
    "norm_q = np.linalg.norm(query_vector)\n",
    "cosine_q = query_vector.dot(query_vector)\n",
    "print(f\"Normalised length of the embedding vector: {norm_q}\")\n",
    "print(f\"Cosine of the query vector with itself: {cosine_q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126ed504-3981-47af-8318-ba184b8fccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between the vector for the query and the vector for the document: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "# Q2. Cosine similarity with another vector\n",
    "\n",
    "document = \"Can I still join the course after the start date?\"\n",
    "document_embeddings_generator = embedding_model.embed(document)\n",
    "document_embeddings_list = list(document_embeddings_generator)\n",
    "document_vector = document_embeddings_list[0]\n",
    "\n",
    "cosine_similarity = query_vector.dot(document_vector)\n",
    "\n",
    "print(f\"Cosine similarity between the vector for the query and the vector for the document: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9e12da-fac1-4060-b5b1-371b568345ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "  Document 0: 0.7630\n",
      "  Document 1: 0.8182\n",
      "  Document 2: 0.8085\n",
      "  Document 3: 0.7133\n",
      "  Document 4: 0.7304\n",
      "\n",
      "Document index with the highest similarity: 1\n",
      "Highest similarity value: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# Q3. Ranking by cosine\n",
    "\n",
    "# define the documents\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "# embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(embedding_model.query_embed(query))[0]\n",
    "\n",
    "# extract and embed document text\n",
    "document_text_items = [doc['text'] for doc in documents]\n",
    "document_embeddings_list = list(embedding_model.embed(document_text_items))\n",
    "\n",
    "# convert list of embeddings to a 2D numpy array\n",
    "embedding_array = np.array(document_embeddings_list)\n",
    "\n",
    "# compute cosine similarity using matrix multiplication\n",
    "cosine_similarities = embedding_array.dot(query_vector)\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for i, similarity in enumerate(cosine_similarities):\n",
    "    print(f\"  Document {i}: {similarity:.4f}\")\n",
    "\n",
    "# find the document with the highest similarity\n",
    "max_similarity_index = np.argmax(cosine_similarities)\n",
    "max_similarity_value = cosine_similarities[max_similarity_index]\n",
    "\n",
    "print(f\"\\nDocument index with the highest similarity: {max_similarity_index}\")\n",
    "print(f\"Highest similarity value: {max_similarity_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a5139d-e335-41ed-86b1-709958beab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "  Document 0: 0.8515\n",
      "  Document 1: 0.8437\n",
      "  Document 2: 0.8408\n",
      "  Document 3: 0.7755\n",
      "  Document 4: 0.8086\n",
      "\n",
      "Document index with the highest similarity: 0\n",
      "Highest similarity value: 0.8515\n"
     ]
    }
   ],
   "source": [
    "# Q4. Ranking by cosine, version two\n",
    "\n",
    "# define the documents\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "# embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(embedding_model.query_embed(query))[0]\n",
    "\n",
    "# create the new full text field for each document and embed\n",
    "document_full_text = []\n",
    "for doc in documents:\n",
    "    full_text = doc['question'] + ' ' + doc['text']\n",
    "    document_full_text.append(full_text)\n",
    "\n",
    "document_embeddings_list = list(embedding_model.embed(document_full_text))\n",
    "\n",
    "# convert list of embeddings to a 2D numpy array\n",
    "embedding_array = np.array(document_embeddings_list)\n",
    "\n",
    "# compute cosine similarity using matrix multiplication\n",
    "cosine_similarities = embedding_array.dot(query_vector)\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for i, similarity in enumerate(cosine_similarities):\n",
    "    print(f\"  Document {i}: {similarity:.4f}\")\n",
    "\n",
    "# find the document with the highest similarity\n",
    "max_similarity_index = np.argmax(cosine_similarities)\n",
    "max_similarity_value = cosine_similarities[max_similarity_index]\n",
    "\n",
    "print(f\"\\nDocument index with the highest similarity: {max_similarity_index}\")\n",
    "print(f\"Highest similarity value: {max_similarity_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edee3efd-73fd-4cd4-bb05-ddca9c6b66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The smallest dimensionality for models in fastembed is: 384\n",
      "\n",
      "Model(s) with this smallest dimensionality:\n",
      "- BAAI/bge-small-en \n",
      "\tDescription: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year. \n",
      "\tDimension: 384\n",
      "- BAAI/bge-small-en-v1.5 \n",
      "\tDescription: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year. \n",
      "\tDimension: 384\n",
      "- snowflake/snowflake-arctic-embed-xs \n",
      "\tDescription: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year. \n",
      "\tDimension: 384\n",
      "- snowflake/snowflake-arctic-embed-s \n",
      "\tDescription: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year. \n",
      "\tDimension: 384\n",
      "- sentence-transformers/all-MiniLM-L6-v2 \n",
      "\tDescription: Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year. \n",
      "\tDimension: 384\n",
      "- sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 \n",
      "\tDescription: Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year. \n",
      "\tDimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Q5. Selecting the embedding model\n",
    "\n",
    "supported_models = TextEmbedding.list_supported_models()\n",
    "all_dimensions = [model['dim'] for model in supported_models if 'dim' in model]\n",
    "smallest_dimension = min(all_dimensions)\n",
    "\n",
    "print(f\"\\nThe smallest dimensionality for models in fastembed is: {smallest_dimension}\")\n",
    "\n",
    "models_with_smallest_dim = [\n",
    "    model_info for model_info in supported_models\n",
    "    if 'dim' in model_info and model_info['dim'] == smallest_dimension\n",
    "]\n",
    "\n",
    "if models_with_smallest_dim:\n",
    "    print(f\"\\nModel(s) with this smallest dimensionality:\")\n",
    "    for model_info in models_with_smallest_dim:\n",
    "        print(f\"- {model_info['model']} \\n\\tDescription: {model_info.get('description', 'N/A')} \\n\\tDimension: {model_info.get('dim', 'N/A')}\")\n",
    "else:\n",
    "    print(\"Could not find a model with this smallest dimensionality.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60f44f6c-ca87-45fa-9cde-aa3e38ee74b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'ml_zoomcamp_faq' already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Q6. Indexing with qdrant (2 points)\n",
    "\n",
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\") # connecting to the local Qdrant instance\n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "COLLECTION_NAME = \"ml_zoomcamp_faq\"\n",
    "\n",
    "# Create the collection with specified vector parameters (only if the collection doesn't already exist)\n",
    "if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    print(f\"Collection '{COLLECTION_NAME}' already exists. Skipping creation.\")\n",
    "else:\n",
    "    client.create_collection(\n",
    "        collection_name = COLLECTION_NAME,\n",
    "        vectors_config = models.VectorParams(\n",
    "            size = EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "            distance = models.Distance.COSINE  # Distance metric for similarity search\n",
    "        )\n",
    "    )\n",
    "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
    "\n",
    "# Generate embeddings and prepare points for Qdrant\n",
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        # concatenate question and text fields\n",
    "        full_text = doc['question'] + ' ' + doc['text']\n",
    "\n",
    "        # embed full text for the document\n",
    "        doc_embedding_vector = list(embedding_model.embed(full_text))[0]\n",
    "        \n",
    "        point = models.PointStruct(\n",
    "            id = id,\n",
    "            vector = doc_embedding_vector.tolist(), \n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"question\": doc['question'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e05f0ac3-5b89-418a-aee3-37297cbd678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name = COLLECTION_NAME,\n",
    "    points = points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44607737-5f98-4ec7-9b45-567453317c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points=[ScoredPoint(id=449, version=1, score=0.87031734, payload={'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)]\n",
      "\n",
      "Highest score in the search results (for the first returned record): 0.87031734\n"
     ]
    }
   ],
   "source": [
    "# perform the search\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(embedding_model.query_embed(query))[0]\n",
    "\n",
    "search_results = client.query_points(\n",
    "    collection_name = COLLECTION_NAME,\n",
    "    query = query_vector.tolist(),\n",
    "    limit = 1,\n",
    "    with_payload = True #to get metadata in the results# Only need the top result\n",
    ")\n",
    "\n",
    "print(search_results)\n",
    "print(f\"\\nHighest score in the search results (for the first returned record): {search_results.points[0].score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0c29d-5872-40ed-80bd-bbc84b4b4c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c11c9c-6bab-4499-b9af-68b34493c926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
